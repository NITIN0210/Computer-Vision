{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#!/usr/bin/env python3\r\n",
    "\r\n",
    "from pathlib import Path\r\n",
    "import sys\r\n",
    "import cv2\r\n",
    "import depthai as dai\r\n",
    "import numpy as np\r\n",
    "import time\r\n",
    "\r\n",
    "\r\n",
    "model_blob_path = 'yolo-v4-tiny-tf_openvino_2021.4_6shave.blob'\r\n",
    "# Tiny yolo v4 label texts\r\n",
    "labelMap = [\r\n",
    "    \"person\",         \"bicycle\",    \"car\",           \"motorbike\",     \"aeroplane\",   \"bus\",           \"train\",\r\n",
    "    \"truck\",          \"boat\",       \"traffic light\", \"fire hydrant\",  \"stop sign\",   \"parking meter\", \"bench\",\r\n",
    "    \"bird\",           \"cat\",        \"dog\",           \"horse\",         \"sheep\",       \"cow\",           \"elephant\",\r\n",
    "    \"bear\",           \"zebra\",      \"giraffe\",       \"backpack\",      \"umbrella\",    \"handbag\",       \"tie\",\r\n",
    "    \"suitcase\",       \"frisbee\",    \"skis\",          \"snowboard\",     \"sports ball\", \"kite\",          \"baseball bat\",\r\n",
    "    \"baseball glove\", \"skateboard\", \"surfboard\",     \"tennis racket\", \"bottle\",      \"wine glass\",    \"cup\",\r\n",
    "    \"fork\",           \"knife\",      \"spoon\",         \"bowl\",          \"banana\",      \"apple\",         \"sandwich\",\r\n",
    "    \"orange\",         \"broccoli\",   \"carrot\",        \"hot dog\",       \"pizza\",       \"donut\",         \"cake\",\r\n",
    "    \"chair\",          \"sofa\",       \"pottedplant\",   \"bed\",           \"diningtable\", \"toilet\",        \"tvmonitor\",\r\n",
    "    \"laptop\",         \"mouse\",      \"remote\",        \"keyboard\",      \"cell phone\",  \"microwave\",     \"oven\",\r\n",
    "    \"toaster\",        \"sink\",       \"refrigerator\",  \"book\",          \"clock\",       \"vase\",          \"scissors\",\r\n",
    "    \"teddy bear\",     \"hair drier\", \"toothbrush\"\r\n",
    "]\r\n",
    "\r\n",
    "syncNN = True\r\n",
    "\r\n",
    "# Create pipeline\r\n",
    "pipeline = dai.Pipeline()\r\n",
    "\r\n",
    "# Define sources and outputs\r\n",
    "camRgb = pipeline.create(dai.node.ColorCamera)\r\n",
    "spatialDetectionNetwork = pipeline.create(dai.node.YoloSpatialDetectionNetwork)\r\n",
    "monoLeft = pipeline.create(dai.node.MonoCamera)\r\n",
    "monoRight = pipeline.create(dai.node.MonoCamera)\r\n",
    "stereo = pipeline.create(dai.node.StereoDepth)\r\n",
    "\r\n",
    "xoutRgb = pipeline.create(dai.node.XLinkOut)\r\n",
    "xoutNN = pipeline.create(dai.node.XLinkOut)\r\n",
    "xoutBoundingBoxDepthMapping = pipeline.create(dai.node.XLinkOut)\r\n",
    "xoutDepth = pipeline.create(dai.node.XLinkOut)\r\n",
    "\r\n",
    "xoutRgb.setStreamName(\"rgb\")\r\n",
    "xoutNN.setStreamName(\"detections\")\r\n",
    "xoutBoundingBoxDepthMapping.setStreamName(\"boundingBoxDepthMapping\")\r\n",
    "xoutDepth.setStreamName(\"depth\")\r\n",
    "\r\n",
    "# Properties\r\n",
    "camRgb.setPreviewSize(416, 416)\r\n",
    "camRgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\r\n",
    "camRgb.setInterleaved(False)\r\n",
    "camRgb.setColorOrder(dai.ColorCameraProperties.ColorOrder.BGR)\r\n",
    "\r\n",
    "monoLeft.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\r\n",
    "monoLeft.setBoardSocket(dai.CameraBoardSocket.LEFT)\r\n",
    "monoRight.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\r\n",
    "monoRight.setBoardSocket(dai.CameraBoardSocket.RIGHT)\r\n",
    "\r\n",
    "# setting node configs\r\n",
    "stereo.setDefaultProfilePreset(dai.node.StereoDepth.PresetMode.HIGH_DENSITY)\r\n",
    "\r\n",
    "spatialDetectionNetwork.setBlobPath(model_blob_path)\r\n",
    "spatialDetectionNetwork.setConfidenceThreshold(0.5)\r\n",
    "spatialDetectionNetwork.input.setBlocking(False)\r\n",
    "spatialDetectionNetwork.setBoundingBoxScaleFactor(0.5)\r\n",
    "spatialDetectionNetwork.setDepthLowerThreshold(100)\r\n",
    "spatialDetectionNetwork.setDepthUpperThreshold(5000)\r\n",
    "\r\n",
    "# Yolo specific parameters\r\n",
    "spatialDetectionNetwork.setNumClasses(80)\r\n",
    "spatialDetectionNetwork.setCoordinateSize(4)\r\n",
    "spatialDetectionNetwork.setAnchors(np.array([10,14, 23,27, 37,58, 81,82, 135,169, 344,319]))\r\n",
    "spatialDetectionNetwork.setAnchorMasks({ \"side26\": np.array([1,2,3]), \"side13\": np.array([3,4,5]) })\r\n",
    "spatialDetectionNetwork.setIouThreshold(0.5)\r\n",
    "\r\n",
    "# Linking\r\n",
    "monoLeft.out.link(stereo.left)\r\n",
    "monoRight.out.link(stereo.right)\r\n",
    "\r\n",
    "camRgb.preview.link(spatialDetectionNetwork.input)\r\n",
    "if syncNN:\r\n",
    "    spatialDetectionNetwork.passthrough.link(xoutRgb.input)\r\n",
    "else:\r\n",
    "    camRgb.preview.link(xoutRgb.input)\r\n",
    "\r\n",
    "spatialDetectionNetwork.out.link(xoutNN.input)\r\n",
    "spatialDetectionNetwork.boundingBoxMapping.link(xoutBoundingBoxDepthMapping.input)\r\n",
    "\r\n",
    "stereo.depth.link(spatialDetectionNetwork.inputDepth)\r\n",
    "spatialDetectionNetwork.passthroughDepth.link(xoutDepth.input)\r\n",
    "\r\n",
    "# Connect to device and start pipeline\r\n",
    "with dai.Device(pipeline, True) as device:\r\n",
    "\r\n",
    "    # Output queues will be used to get the rgb frames and nn data from the outputs defined above\r\n",
    "    previewQueue = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\r\n",
    "    detectionNNQueue = device.getOutputQueue(name=\"detections\", maxSize=4, blocking=False)\r\n",
    "    xoutBoundingBoxDepthMappingQueue = device.getOutputQueue(name=\"boundingBoxDepthMapping\", maxSize=4, blocking=False)\r\n",
    "    depthQueue = device.getOutputQueue(name=\"depth\", maxSize=4, blocking=False)\r\n",
    "\r\n",
    "    startTime = time.monotonic()\r\n",
    "    counter = 0\r\n",
    "    fps = 0\r\n",
    "    color = (255, 255, 255)\r\n",
    "\r\n",
    "    while True:\r\n",
    "        inPreview = previewQueue.get()\r\n",
    "        inDet = detectionNNQueue.get()\r\n",
    "        depth = depthQueue.get()\r\n",
    "\r\n",
    "        frame = inPreview.getCvFrame()\r\n",
    "        depthFrame = depth.getFrame()\r\n",
    "        depthFrameColor = cv2.normalize(depthFrame, None, 255, 0, cv2.NORM_INF, cv2.CV_8UC1)\r\n",
    "        depthFrameColor = cv2.equalizeHist(depthFrameColor)\r\n",
    "        depthFrameColor = cv2.applyColorMap(depthFrameColor, cv2.COLORMAP_HOT)\r\n",
    "\r\n",
    "        counter+=1\r\n",
    "        current_time = time.monotonic()\r\n",
    "        if (current_time - startTime) > 1 :\r\n",
    "            fps = counter / (current_time - startTime)\r\n",
    "            counter = 0\r\n",
    "            startTime = current_time\r\n",
    "\r\n",
    "        detections = inDet.detections\r\n",
    "        if len(detections) != 0:\r\n",
    "            boundingBoxMapping = xoutBoundingBoxDepthMappingQueue.get()\r\n",
    "            roiDatas = boundingBoxMapping.getConfigData()\r\n",
    "\r\n",
    "            for roiData in roiDatas:\r\n",
    "                roi = roiData.roi\r\n",
    "                roi = roi.denormalize(depthFrameColor.shape[1], depthFrameColor.shape[0])\r\n",
    "                topLeft = roi.topLeft()\r\n",
    "                bottomRight = roi.bottomRight()\r\n",
    "                xmin = int(topLeft.x)\r\n",
    "                ymin = int(topLeft.y)\r\n",
    "                xmax = int(bottomRight.x)\r\n",
    "                ymax = int(bottomRight.y)\r\n",
    "\r\n",
    "                cv2.rectangle(depthFrameColor, (xmin, ymin), (xmax, ymax), color, cv2.FONT_HERSHEY_SCRIPT_SIMPLEX)\r\n",
    "\r\n",
    "\r\n",
    "        # If the frame is available, draw bounding boxes on it and show the frame\r\n",
    "        height = frame.shape[0]\r\n",
    "        width  = frame.shape[1]\r\n",
    "        for detection in detections:\r\n",
    "            # Denormalize bounding box\r\n",
    "            x1 = int(detection.xmin * width)\r\n",
    "            x2 = int(detection.xmax * width)\r\n",
    "            y1 = int(detection.ymin * height)\r\n",
    "            y2 = int(detection.ymax * height)\r\n",
    "            try:\r\n",
    "                label = labelMap[detection.label]\r\n",
    "            except:\r\n",
    "                label = detection.label\r\n",
    "            cv2.putText(frame, str(label), (x1 + 10, y1 + 20), cv2.FONT_HERSHEY_TRIPLEX, 0.5, 255)\r\n",
    "            cv2.putText(frame, \"{:.2f}\".format(detection.confidence*100), (x1 + 10, y1 + 35), cv2.FONT_HERSHEY_TRIPLEX, 0.5, 255)\r\n",
    "            cv2.putText(frame, f\"X: {int(detection.spatialCoordinates.x)} mm\", (x1 + 10, y1 + 50), cv2.FONT_HERSHEY_TRIPLEX, 0.5, 255)\r\n",
    "            cv2.putText(frame, f\"Y: {int(detection.spatialCoordinates.y)} mm\", (x1 + 10, y1 + 65), cv2.FONT_HERSHEY_TRIPLEX, 0.5, 255)\r\n",
    "            cv2.putText(frame, f\"Z: {int(detection.spatialCoordinates.z)} mm\", (x1 + 10, y1 + 80), cv2.FONT_HERSHEY_TRIPLEX, 0.5, 255)\r\n",
    "\r\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, cv2.FONT_HERSHEY_SIMPLEX)\r\n",
    "\r\n",
    "        cv2.putText(frame, \"NN fps: {:.2f}\".format(fps), (2, frame.shape[0] - 4), cv2.FONT_HERSHEY_TRIPLEX, 0.4, color)\r\n",
    "        cv2.imshow(\"depth\", depthFrameColor)\r\n",
    "        cv2.imshow(\"rgb\", frame)\r\n",
    "\r\n",
    "        if cv2.waitKey(1) == ord('q'):\r\n",
    "            break\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Cannot load blob, file at path yolo-v4-tiny-tf_openvino_2021.4_6shave.blob doesn't exist.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# setting node configs\u001b[39;00m\n\u001b[0;32m     62\u001b[0m stereo\u001b[38;5;241m.\u001b[39msetDefaultProfilePreset(dai\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mStereoDepth\u001b[38;5;241m.\u001b[39mPresetMode\u001b[38;5;241m.\u001b[39mHIGH_DENSITY)\n\u001b[1;32m---> 64\u001b[0m \u001b[43mspatialDetectionNetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetBlobPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_blob_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m spatialDetectionNetwork\u001b[38;5;241m.\u001b[39msetConfidenceThreshold(\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m     66\u001b[0m spatialDetectionNetwork\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m.\u001b[39msetBlocking(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot load blob, file at path yolo-v4-tiny-tf_openvino_2021.4_6shave.blob doesn't exist."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import cv2\r\n",
    "\r\n",
    "print(\"Output of the object detection- \")\r\n",
    "\r\n",
    "plt.imshow(cv2.imread(\"od_1.png\")[:,:,::-1])\r\n",
    "plt.show()\r\n",
    "plt.imshow(cv2.imread(\"od_2.png\")[:,:,::-1])\r\n",
    "plt.show()\r\n",
    "plt.imshow(cv2.imread(\"od_3.png\")[:,:,::-1])\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('cvFall22': venv)"
  },
  "interpreter": {
   "hash": "52e41782f98fb38972ac69e0e4a1cd20464197d6de4aa3423c902988ca4cc3bb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}