{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#!/usr/bin/env python3\r\n",
    "\r\n",
    "from pathlib import Path\r\n",
    "import cv2\r\n",
    "import depthai as dai\r\n",
    "import numpy as np\r\n",
    "import time\r\n",
    "import argparse\r\n",
    "\r\n",
    "default_nn = str((Path(__file__).parent / Path('models/face-detection-retail-0004_openvino_2021.2_4shave.blob')).resolve().absolute())\r\n",
    "parser = argparse.ArgumentParser()\r\n",
    "parser.add_argument('mobilenet_path', nargs='?', help=\"Path to mobilenet detection network blob\", default=default_nn)\r\n",
    "parser.add_argument('-s', '--sync', action=\"store_true\", help=\"Sync RGB output with NN output\", default=False)\r\n",
    "args = parser.parse_args()\r\n",
    "\r\n",
    "# Start defining a pipeline\r\n",
    "pipeline = dai.Pipeline()\r\n",
    "\r\n",
    "# Define a source - color camera\r\n",
    "cam_rgb = pipeline.createColorCamera()\r\n",
    "cam_rgb.setPreviewSize(300, 300)\r\n",
    "cam_rgb.setInterleaved(False)\r\n",
    "cam_rgb.setFps(40)\r\n",
    "\r\n",
    "# Define a neural network that will make predictions based on the source frames\r\n",
    "detection_nn = pipeline.createMobileNetDetectionNetwork()\r\n",
    "detection_nn.setConfidenceThreshold(0.5)\r\n",
    "detection_nn.setBlobPath(args.mobilenet_path)\r\n",
    "detection_nn.setNumInferenceThreads(2)\r\n",
    "detection_nn.input.setBlocking(False)\r\n",
    "cam_rgb.preview.link(detection_nn.input)\r\n",
    "\r\n",
    "# Create outputs\r\n",
    "xout_rgb = pipeline.createXLinkOut()\r\n",
    "xout_rgb.setStreamName(\"rgb\")\r\n",
    "if(args.sync):\r\n",
    "    detection_nn.passthrough.link(xout_rgb.input)\r\n",
    "else:\r\n",
    "    cam_rgb.preview.link(xout_rgb.input)\r\n",
    "\r\n",
    "xout_nn = pipeline.createXLinkOut()\r\n",
    "xout_nn.setStreamName(\"nn\")\r\n",
    "detection_nn.out.link(xout_nn.input)\r\n",
    "\r\n",
    "\r\n",
    "# Pipeline defined, now the device is connected to\r\n",
    "with dai.Device(pipeline) as device:\r\n",
    "    # Start pipeline\r\n",
    "    device.startPipeline()\r\n",
    "\r\n",
    "    # Output queues will be used to get the rgb frames and nn data from the outputs defined above\r\n",
    "    q_rgb = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\r\n",
    "    q_nn = device.getOutputQueue(name=\"nn\", maxSize=4, blocking=False)\r\n",
    "\r\n",
    "    start_time = time.monotonic()\r\n",
    "    counter = 0\r\n",
    "    detections = []\r\n",
    "    frame = None\r\n",
    "\r\n",
    "    # nn data (bounding box locations) are in <0..1> range - they need to be normalized with frame width/height\r\n",
    "    def frame_norm(frame, bbox):\r\n",
    "        norm_vals = np.full(len(bbox), frame.shape[0])\r\n",
    "        norm_vals[::2] = frame.shape[1]\r\n",
    "        return (np.clip(np.array(bbox), 0, 1) * norm_vals).astype(int)\r\n",
    "\r\n",
    "\r\n",
    "    while True:\r\n",
    "        if(args.sync):\r\n",
    "            # use blocking get() call to catch frame and inference result synced\r\n",
    "            in_rgb = q_rgb.get()\r\n",
    "            in_nn = q_nn.get()\r\n",
    "        else:\r\n",
    "            # instead of get (blocking) used tryGet (nonblocking) which will return the available data or None otherwise\r\n",
    "            in_rgb = q_rgb.tryGet()\r\n",
    "            in_nn = q_nn.tryGet()\r\n",
    "\r\n",
    "        if in_rgb is not None:\r\n",
    "            frame = in_rgb.getCvFrame()\r\n",
    "            cv2.putText(frame, \"NN fps: {:.2f}\".format(counter / (time.monotonic() - start_time)),\r\n",
    "                        (2, frame.shape[0] - 4), cv2.FONT_HERSHEY_TRIPLEX, 0.4, color=(255, 255, 255))\r\n",
    "\r\n",
    "        if in_nn is not None:\r\n",
    "            detections = in_nn.detections\r\n",
    "            counter += 1\r\n",
    "\r\n",
    "        # if the frame is available, draw bounding boxes on it and show the frame\r\n",
    "        if frame is not None:\r\n",
    "            for detection in detections:\r\n",
    "                bbox = frame_norm(frame, (detection.xmin, detection.ymin, detection.xmax, detection.ymax))\r\n",
    "                cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 0, 0), 2)\r\n",
    "\r\n",
    "            cv2.imshow(\"rgb\", frame)\r\n",
    "\r\n",
    "        if cv2.waitKey(1) == ord('q'):\r\n",
    "            break\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-s] [mobilenet_path]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9008 --control=9006 --hb=9005 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"72997648-1f97-4692-b683-59d2c17d7c8b\" --shell=9007 --transport=\"tcp\" --iopub=9009 --f=C:\\Users\\NITINK~1\\AppData\\Local\\Temp\\tmp-138562JCM0X8QxNnB.json\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "SystemExit",
     "evalue": "2",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "e:\\u\\sem1\\cv\\cvFall22\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('cvFall22': venv)"
  },
  "interpreter": {
   "hash": "52e41782f98fb38972ac69e0e4a1cd20464197d6de4aa3423c902988ca4cc3bb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}